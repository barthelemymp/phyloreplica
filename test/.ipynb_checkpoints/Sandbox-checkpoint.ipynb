{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b29aac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys, os\n",
    "sys.path.append('C:\\\\Users\\\\bartm\\\\Documents\\\\These\\\\phyloreplica\\\\src')\n",
    "from PhyloDataset import *\n",
    "from PhyloTrees import *\n",
    "from vae import *\n",
    "import torch\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "datapath1 = \"../data/PF00072/PF00072_rp15_has_PF00196.faa\"\n",
    "datapath2 = \"../data/PF00072/PF00072_rp15_has_PF00486.faa\"\n",
    "datapath3 = \"../data/PF00072/PF00072_rp15_has_PF00512.faa\"\n",
    "datapath4 = \"data/PF00072/PF00072_rp15_has_PF00158.faa\"\n",
    "datapath5 = \"data/PF00072/PF00072_rp15_has_PF00990.faa\"\n",
    "datapath6 = \"data/PF00072/PF00072_rp15_has_PF01339.faa\"\n",
    "datapath7 = \"data/PF00072/PF00072_rp15_has_PF04397.faa\"\n",
    "datapath8 = \"data/PF00072/PF00072_rp15_has_PF12833.faa\"\n",
    "\n",
    "lossfn = vae_loss\n",
    "\n",
    "dataset1 = MSA(datapath1)\n",
    "dataset2 = MSA(datapath2)\n",
    "dataset3 = MSA(datapath3)\n",
    "lt = len(dataset1) + len(dataset2) + len(dataset1)\n",
    "l1 = int(32*len(dataset1)/lt) \n",
    "l2 = int(32*len(dataset2)/lt) \n",
    "l3 = 32 - l1 -l2\n",
    "\n",
    "vae1 = VAE(21, 5, dataset1.len_protein * dataset1.q, [512, 256, 128])\n",
    "optimizer1 = optim.Adam(vae1.parameters(),weight_decay=0.01)\n",
    "Node1 = PhyloNode(vae1,\n",
    "          optimizer1, \n",
    "          lossfn,\n",
    "          parent=None, \n",
    "          children=[], \n",
    "          dataset = dataset1, \n",
    "          tuplesize=2, \n",
    "          batch_size=l1, \n",
    "          gammaManager = gammaManager_Independant(),\n",
    "          Name = \"196\"\n",
    "    )\n",
    "\n",
    "\n",
    "vae2 = VAE(21, 5, dataset2.len_protein * dataset2.q, [512, 256, 128])\n",
    "optimizer2 = optim.Adam(vae2.parameters(),weight_decay=0.01)\n",
    "Node2 = PhyloNode(vae2,\n",
    "          optimizer2, \n",
    "          lossfn,\n",
    "          parent=None, \n",
    "          children=[], \n",
    "          dataset = dataset2, \n",
    "          tuplesize=2, \n",
    "          batch_size=l2, \n",
    "          gammaManager = gammaManager_Independant(),\n",
    "          Name=\"486\"\n",
    "    )\n",
    "\n",
    "\n",
    "vae3 = VAE(21, 5, dataset3.len_protein * dataset3.q, [512, 256, 128])\n",
    "optimizer3 = optim.Adam(vae3.parameters(),weight_decay=0.01)\n",
    "Node3 = PhyloNode(vae3,\n",
    "          optimizer3, \n",
    "          lossfn,\n",
    "          parent=None, \n",
    "          children=[], \n",
    "          dataset = dataset3, \n",
    "          tuplesize=2, \n",
    "          batch_size=l3, \n",
    "          gammaManager = gammaManager_Independant(),\n",
    "          Name=\"512\"\n",
    "    )\n",
    "\n",
    "vaeR =  VAE(21, 5, dataset3.len_protein * dataset3.q, [512, 256, 128])\n",
    "optimizerR = optim.Adam(vaeR.parameters(),weight_decay=0.01)\n",
    "NodeR = PhyloNode(vaeR,\n",
    "          optimizer3, \n",
    "          lossfn,\n",
    "          parent=None, \n",
    "          children=[], \n",
    "          dataset = dataset3, \n",
    "          tuplesize=2, \n",
    "          batch_size=32, \n",
    "          gammaManager = gammaManager_Independant(),\n",
    "          Name=\"Root\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177183a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e1356f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed362e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f458e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "mean(): argument 'input' (position 1) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24496/2175512283.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#         loss += l2_lambda * l2_reg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" acc train\"\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mtest_loss_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: mean(): argument 'input' (position 1) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    print(epoch)\n",
    "    vae1.train()\n",
    "    train_loss_list = []\n",
    "    for batch_idx, batch in enumerate(Node1.train_iterator):\n",
    "        x,w = batch[0], batch[1]\n",
    "        #targ = targ.unsqueeze(1)\n",
    "        loss = -vae1.compute_weighted_elbo(x, w)\n",
    "        optimizer1.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "        train_loss_list.append(loss.item())\n",
    "    \n",
    "#         l2_reg = torch.tensor(0.)\n",
    "#         for param in Dcla.parameters():\n",
    "#             l2_reg += torch.norm(param)\n",
    "#         loss += l2_lambda * l2_reg\n",
    "\n",
    "    print(\" acc train\" ,np.mean(train_loss_list))\n",
    "    scheduler.step(torch.mean(train_loss_list))\n",
    "    test_loss_list = []\n",
    "    with  torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(Node1.test_iterator):\n",
    "            x,w = batch[0], batch[1]\n",
    "            loss = -vae1.compute_weighted_elbo(x, w)\n",
    "            test_loss_list.append(loss.item())\n",
    "    print(\" acc val\" ,np.mean(test_loss_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e9d992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

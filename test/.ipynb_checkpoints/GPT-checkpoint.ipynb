{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99846bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys, os\n",
    "sys.path.append('C:\\\\Users\\\\bartm\\\\Documents\\\\These\\\\phyloreplica\\\\src')\n",
    "from PhyloDataset import *\n",
    "from PhyloTrees import *\n",
    "\n",
    "from vae import *\n",
    "from GProT import *\n",
    "import torch\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "datapath1 = \"../data/PF00072/PF00072_rp15_has_PF00196.faa\"\n",
    "datapath2 = \"../data/PF00072/PF00072_rp15_has_PF00486.faa\"\n",
    "datapath3 = \"../data/PF00072/PF00072_rp15_has_PF00512.faa\"\n",
    "datapath4 = \"data/PF00072/PF00072_rp15_has_PF00158.faa\"\n",
    "datapath5 = \"data/PF00072/PF00072_rp15_has_PF00990.faa\"\n",
    "datapath6 = \"data/PF00072/PF00072_rp15_has_PF01339.faa\"\n",
    "datapath7 = \"data/PF00072/PF00072_rp15_has_PF04397.faa\"\n",
    "datapath8 = \"data/PF00072/PF00072_rp15_has_PF12833.faa\"\n",
    "\n",
    "device=\"cuda\"\n",
    "dataset1 = MSA(datapath1,onehot=False, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eda3285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dba209e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1.q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f3f543",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd641146",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    r\"\"\"Inject some information about the relative or absolute position of the tokens\n",
    "        in the sequence. The positional encodings have the same dimension as\n",
    "        the embeddings, so that the two can be summed. Here, we use sine and cosine\n",
    "        functions of different frequencies.\n",
    "    .. math::\n",
    "        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
    "        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
    "        \\text{where pos is the word position and i is the embed idx)\n",
    "    Args:\n",
    "        d_model: the embed dim (required).\n",
    "        dropout: the dropout value (default=0.1).\n",
    "        max_len: the max. length of the incoming sequence (default=5000).\n",
    "    Examples:\n",
    "        >>> pos_encoder = PositionalEncoding(d_model)\n",
    "    source: https://github.com/pytorch/tutorials/blob/011ae8a6d47a960935d0401acda71d0e400088d6/advanced_source/ddp_pipeline.py#L43\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=25,device='cpu'):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.device = device\n",
    "        pe = torch.zeros(max_len, d_model).to(device)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)[:,:pe[:, 0::2].shape[1]]\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)[:,:pe[:, 1::2].shape[1]]\n",
    "        #pe = pe[:,:-1] #this step is not really smart, needed when d_model is odd. \n",
    "        pe = pe.unsqueeze(0)#.transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "        print(self.pe.device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        r\"\"\"Inputs of forward function\n",
    "        Args:\n",
    "            x: the sequence fed to the positional encoder model (required).\n",
    "        Shape:\n",
    "            x: [sequence length, batch size, embed dim]\n",
    "            output: [sequence length, batch size, embed dim]\n",
    "        Examples:\n",
    "            >>> output = pos_encoder(x)\n",
    "        \"\"\"\n",
    "        #print( self.pe[:x.size(0), :].shape)\n",
    "        \n",
    "        x = (x + self.pe[:, :x.size(1)]).to(self.device)\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GPTConfig:\n",
    "    \"\"\" base GPT config, params common to all GPT versions \"\"\"\n",
    "    embd_pdrop = 0.1\n",
    "    resid_pdrop = 0.1\n",
    "    attn_pdrop = 0.1\n",
    "\n",
    "    def __init__(self, vocab_size, block_size, **kwargs):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.block_size = block_size\n",
    "        for k,v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "class GPT1Config(GPTConfig):\n",
    "    \"\"\" GPT-1 like network roughly 125M params \"\"\"\n",
    "    n_layer = 12\n",
    "    n_head = 12\n",
    "    n_embd = 768\n",
    "\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    A vanilla multi-head masked self-attention layer with a projection at the end.\n",
    "    It is possible to use torch.nn.MultiheadAttention here but I am including an\n",
    "    explicit implementation here to show that there is nothing too scary here.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projections for all heads\n",
    "        self.key = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.query = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.value = nn.Linear(config.n_embd, config.n_embd)\n",
    "        # regularization\n",
    "        self.attn_drop = nn.Dropout(config.attn_pdrop)\n",
    "        self.resid_drop = nn.Dropout(config.resid_pdrop)\n",
    "        # output projection\n",
    "        self.proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        # causal mask to ensure that attention is only applied to the left in the input sequence\n",
    "        self.register_buffer(\"mask\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                                     .view(1, 1, config.block_size, config.block_size))\n",
    "        self.n_head = config.n_head\n",
    "\n",
    "    def forward(self, x, layer_past=None):\n",
    "        B, T, C = x.size()\n",
    "\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        k = self.key(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        q = self.query(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = self.value(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "\n",
    "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
    "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "        att = att.masked_fill(self.mask[:,:,:T,:T] == 0, float('-inf'))\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        att = self.attn_drop(att)\n",
    "        # print(\"attshape\", att.shape)\n",
    "        # print(att[0,0,:10,:10])\n",
    "        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "\n",
    "        # output projection\n",
    "        \n",
    "        y = self.resid_drop(self.proj(y))\n",
    "\n",
    "        return y\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" an unassuming Transformer block \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(config.n_embd)#n_embd\n",
    "        self.ln2 = nn.LayerNorm(config.n_embd)#n_embd\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(config.n_embd, 4*config.n_embd),#n_embd-4n_embd\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4*config.n_embd, config.n_embd),#4n_embd-n_embd\n",
    "            nn.Dropout(config.resid_pdrop),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(self.attn(self.ln1(x))[0,0])\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    \"\"\"  the full GPT language model, with a context size of block_size \"\"\"\n",
    "\n",
    "    def __init__(self, config, device):\n",
    "        super().__init__()\n",
    "\n",
    "        # input embedding stem\n",
    "        self.vocab_size = config.vocab_size\n",
    "        self.tok_emb = nn.Embedding(config.vocab_size, config.n_embd)\n",
    "        # self.pos_emb = nn.Parameter(torch.zeros(1, config.block_size, config.n_embd))\n",
    "        self.position_embedding = PositionalEncoding(config.n_embd, max_len=config.block_size, device=device)\n",
    "        self.drop = nn.Dropout(config.embd_pdrop)\n",
    "        self.device = device\n",
    "        # transformer\n",
    "        self.blocks = nn.Sequential(*[Block(config) for _ in range(config.n_layer)])\n",
    "        # decoder head\n",
    "        self.ln_f = nn.LayerNorm(config.n_embd)#n_embd\n",
    "        self.head = nn.Linear(config.n_embd, config.vocab_size, bias=False)#n_embd#n_embd\n",
    "\n",
    "        self.block_size = config.block_size\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "        logger.info(\"number of parameters: %e\", sum(p.numel() for p in self.parameters()))\n",
    "\n",
    "    def get_block_size(self):\n",
    "        return self.block_size\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def configure_optimizers(self, train_config):\n",
    "        \"\"\"\n",
    "        This long function is unfortunately doing something very simple and is being very defensive:\n",
    "        We are separating out all parameters of the model into two buckets: those that will experience\n",
    "        weight decay for regularization and those that won't (biases, and layernorm/embedding weights).\n",
    "        We are then returning the PyTorch optimizer object.\n",
    "        \"\"\"\n",
    "\n",
    "        # separate out all parameters to those that will and won't experience regularizing weight decay\n",
    "        decay = set()\n",
    "        no_decay = set()\n",
    "        whitelist_weight_modules = (torch.nn.Linear, )\n",
    "        blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.Embedding)\n",
    "        for mn, m in self.named_modules():\n",
    "            for pn, p in m.named_parameters():\n",
    "                fpn = '%s.%s' % (mn, pn) if mn else pn # full param name\n",
    "\n",
    "                if pn.endswith('bias'):\n",
    "                    # all biases will not be decayed\n",
    "                    no_decay.add(fpn)\n",
    "                elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):\n",
    "                    # weights of whitelist modules will be weight decayed\n",
    "                    decay.add(fpn)\n",
    "                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):\n",
    "                    # weights of blacklist modules will NOT be weight decayed\n",
    "                    no_decay.add(fpn)\n",
    "\n",
    "        # special case the position embedding parameter in the root GPT module as not decayed\n",
    "        no_decay.add('pos_emb')\n",
    "\n",
    "        # validate that we considered every parameter\n",
    "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
    "        inter_params = decay & no_decay\n",
    "        union_params = decay | no_decay\n",
    "        assert len(inter_params) == 0, \"parameters %s made it into both decay/no_decay sets!\" % (str(inter_params), )\n",
    "        assert len(param_dict.keys() - union_params) == 0, \"parameters %s were not separated into either decay/no_decay set!\" \\\n",
    "                                                    % (str(param_dict.keys() - union_params), )\n",
    "\n",
    "        # create the pytorch optimizer object\n",
    "        optim_groups = [\n",
    "            {\"params\": [param_dict[pn] for pn in sorted(list(decay))], \"weight_decay\": train_config.weight_decay},\n",
    "            {\"params\": [param_dict[pn] for pn in sorted(list(no_decay))], \"weight_decay\": 0.0},\n",
    "        ]\n",
    "        optimizer = torch.optim.AdamW(optim_groups, lr=train_config.learning_rate, betas=train_config.betas)\n",
    "        return optimizer\n",
    "\n",
    "    def forward(self, seq, targets=None):\n",
    "        b, L= seq.size()\n",
    "        assert L <= self.block_size, \"Cannot forward, model block size is exhausted.\"\n",
    "\n",
    "        # # forward the GPT model\n",
    "        token_embeddings = self.tok_emb(seq.long()) # each index maps to a (learnable) vector\n",
    "        # position_embeddings = self.pos_emb[:, :t, :] # each position maps to a (learnable) vector\n",
    "\n",
    "        x = self.position_embedding(token_embeddings) #self.drop(token_embeddings + position_embeddings)\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.head(x)\n",
    "\n",
    "        # if we are given some desired targets also calculate the loss\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def GPT_loss(model, batch):\n",
    "\n",
    "    inp = model(batch[0][:,:-1])[0].reshape(-1, model.vocab_size)\n",
    "    \n",
    "    tar = batch[0][:,1:].flatten().long()\n",
    "\n",
    "    return F.cross_entropy(inp, tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c410559a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5baf41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocab_size = dataset1.q\n",
    "\n",
    "co = GPT1Config(vocab_size, dataset1.len_protein+2)\n",
    "co.n_layer = 1\n",
    "co.n_head = 1\n",
    "co.n_embd = 50*vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81148933",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT(co, dataset1.device).to(device)\n",
    "train_iterator = DataLoader(dataset1, batch_size=32, shuffle=True)\n",
    "batch = next(iter(train_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "543791d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2619,  0.8037, -0.0776,  ..., -0.5981, -0.5515,  0.0000],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3.2830, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_loss(model, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12c3165d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(3.3457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(5.7969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(5.9814, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(6.0183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(5.1603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(4.6704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(4.1437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(3.6766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(3.2242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(3.1114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(3.2189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(3.1772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(3.0278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(3.0172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(3.0989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.9815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(3.0062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.9565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(3.0287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.9616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.9259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.9393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.9226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.9288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.9237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7899, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.9157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6654, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6748, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5899, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5837, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7594, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5899, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5765, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5769, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6654, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.9335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5658, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4739, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.2942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5902, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5801, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(3.0264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6801, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6748, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5748, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.2839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4748, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.2855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4765, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.2677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.2826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.2838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.2685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.2353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.2507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3658, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.2767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.2812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.2763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.2637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.3384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(3.2724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.4356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.5584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.8236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.6038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n",
      "tensor(2.7604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "yshape torch.Size([6, 113, 1150])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15388/832338571.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0moptimizer1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGPT_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0moptimizer1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Barth\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Barth\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer1 = optim.Adam(model.parameters())\n",
    "for e in range(100):\n",
    "    \n",
    "    for batchidx, batch in enumerate(train_iterator):\n",
    "        optimizer1.zero_grad()\n",
    "        loss = GPT_loss(model, batch)\n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "        print(e, loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2894e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1.SymbolMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5af39ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for batchidx, batch in enumerate(train_iterator):\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a1f169c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1370"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20787b77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
